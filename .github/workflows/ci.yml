name: BCBS Values CI/CD Pipeline

# Workflow triggers: Run on push to main/develop, pull requests, or manual trigger
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allows manual triggering of the workflow

jobs:
  test:
    runs-on: ubuntu-latest
    
    # Set up PostgreSQL service container for database testing
    services:
      postgres:
        image: postgres:13  # Specific version for consistency
        env:
          POSTGRES_USER: bcbs_test
          POSTGRES_PASSWORD: bcbs_test
          POSTGRES_DB: bcbs_test
        ports:
          - 5432:5432  # Map container port to host
        # Health check ensures PostgreSQL is ready before tests run
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    # Check out repository code
    - name: Checkout code
      uses: actions/checkout@v3
    
    # Set up Python environment
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'  # Cache pip dependencies
        
    # Install Python dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        
        # Check if requirements.txt exists
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          # Fall back to installing specific dependencies if no requirements.txt
          echo "requirements.txt not found, installing specific dependencies..."
          pip install flake8 pytest pytest-cov
          pip install flask==2.3.0 flask-sqlalchemy==3.1.0 
          pip install pandas==2.1.0 psycopg2-binary==2.9.9
          pip install python-dotenv==1.0.0 requests==2.31.0
          pip install selenium==4.15.0 webdriver-manager==4.0.0
          pip install sqlalchemy==2.0.0 email-validator==2.1.0
          pip install fastapi==0.103.2 uvicorn==0.23.2 pydantic==2.4.2
          pip install scikit-learn==1.3.0 numpy==1.25.2
          pip install statsmodels==0.14.0 scipy==1.11.2
        fi
        
        # Always install testing utilities
        pip install flake8 pytest pytest-cov pytest-mock
    
    # Run code quality checks
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Check all code but treat issues as warnings rather than errors
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    # Load secrets from GitHub Secrets
    - name: Load environment variables
      # Use GitHub Secrets for sensitive data
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL || 'postgresql://bcbs_test:bcbs_test@localhost:5432/bcbs_test' }}
        PGHOST: ${{ secrets.PGHOST || 'localhost' }}
        PGPORT: ${{ secrets.PGPORT || '5432' }}
        PGDATABASE: ${{ secrets.PGDATABASE || 'bcbs_test' }}
        PGUSER: ${{ secrets.PGUSER || 'bcbs_test' }}
        PGPASSWORD: ${{ secrets.PGPASSWORD || 'bcbs_test' }}
        FLASK_ENV: testing
        FLASK_SECRET_KEY: ${{ secrets.FLASK_SECRET_KEY || 'dev_secret_key_for_testing' }}
        NARRPR_USERNAME: ${{ secrets.NARRPR_USERNAME || 'test_username' }}
        NARRPR_PASSWORD: ${{ secrets.NARRPR_PASSWORD || 'test_password' }}
        PACS_API_KEY: ${{ secrets.PACS_API_KEY || 'test_api_key' }}
      run: |
        # Create .env file for tests that rely on python-dotenv
        echo "DATABASE_URL=$DATABASE_URL" > .env
        echo "PGHOST=$PGHOST" >> .env
        echo "PGPORT=$PGPORT" >> .env
        echo "PGDATABASE=$PGDATABASE" >> .env
        echo "PGUSER=$PGUSER" >> .env
        echo "PGPASSWORD=$PGPASSWORD" >> .env
        echo "FLASK_ENV=$FLASK_ENV" >> .env
        echo "FLASK_SECRET_KEY=$FLASK_SECRET_KEY" >> .env
        echo "NARRPR_USERNAME=$NARRPR_USERNAME" >> .env
        echo "NARRPR_PASSWORD=$NARRPR_PASSWORD" >> .env
        echo "PACS_API_KEY=$PACS_API_KEY" >> .env
        
        # Print confirmation (without exposing secrets)
        echo "Environment variables loaded successfully"
    
    # Run all pytest tests including integration tests
    - name: Run pytest tests
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL || 'postgresql://bcbs_test:bcbs_test@localhost:5432/bcbs_test' }}
        PGHOST: ${{ secrets.PGHOST || 'localhost' }}
        PGPORT: ${{ secrets.PGPORT || '5432' }}
        PGDATABASE: ${{ secrets.PGDATABASE || 'bcbs_test' }}
        PGUSER: ${{ secrets.PGUSER || 'bcbs_test' }}
        PGPASSWORD: ${{ secrets.PGPASSWORD || 'bcbs_test' }}
        FLASK_ENV: testing
      run: |
        # Run pytest with coverage and generate coverage reports
        pytest --cov=. --cov-report=xml --cov-report=html
        
        # Print summary of test results
        echo "Test results summary:"
        pytest --collect-only -q

    # Run the ETL validation process
    - name: Test ETL Validation
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL || 'postgresql://bcbs_test:bcbs_test@localhost:5432/bcbs_test' }}
      run: |
        # Run the ETL validation process in validate-only mode
        python main.py --sources all --validate-only
    
    # Upload test coverage reports
    - name: Upload test reports
      uses: actions/upload-artifact@v3
      with:
        name: test-reports
        path: |
          coverage.xml
          htmlcov/
          validation_results*.json
        if-no-files-found: warn
    
    # Upload config files for reference
    - name: Upload config files
      uses: actions/upload-artifact@v3
      with:
        name: config-files
        path: configs/
        if-no-files-found: warn

  # Frontend build job (if React components are used)
  build-frontend:
    runs-on: ubuntu-latest
    needs: test
    if: success() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    # Check if there are React components that need to be built
    - name: Check for React files
      id: check-react
      run: |
        if [ -f "package.json" ] || [ -d "frontend" ] || [ $(find . -name "*.js" -not -path "*/node_modules/*" | wc -l) -gt 0 ]; then
          echo "React components found, will proceed with frontend build"
          echo "react_exists=true" >> $GITHUB_OUTPUT
        else
          echo "No React components found, skipping frontend build"
          echo "react_exists=false" >> $GITHUB_OUTPUT
        fi
    
    # Set up Node.js only if React components exist
    - name: Set up Node.js
      if: steps.check-react.outputs.react_exists == 'true'
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    # Install frontend dependencies and build (if package.json exists)
    - name: Build frontend
      if: steps.check-react.outputs.react_exists == 'true'
      run: |
        if [ -f "package.json" ]; then
          npm ci
          npm run build
          echo "Frontend built successfully"
        elif [ -d "frontend" ] && [ -f "frontend/package.json" ]; then
          cd frontend
          npm ci
          npm run build
          echo "Frontend built successfully"
        else
          echo "Found React components but no standard build setup, skipping build step"
        fi
    
    # Upload frontend build artifacts if they were created
    - name: Upload frontend build
      if: steps.check-react.outputs.react_exists == 'true'
      uses: actions/upload-artifact@v3
      with:
        name: frontend-build
        path: |
          build/
          dist/
          frontend/build/
          frontend/dist/
        if-no-files-found: ignore

  # Backend build job for deployment
  build-backend:
    needs: test
    runs-on: ubuntu-latest
    if: success() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # Install production dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          echo "requirements.txt not found, creating from installed packages"
          pip install flask fastapi pandas sqlalchemy
          pip freeze > requirements.txt
        fi
    
    # Create deployment package with all necessary files
    - name: Create deployment package
      run: |
        # Create deploy directory
        mkdir -p deploy
        
        # Copy backend files
        cp -r db etl src templates configs tests *.py deploy/
        cp requirements.txt deploy/
        
        # Create build info file
        echo "Build completed on $(date)" > deploy/build_info.txt
        echo "Git commit: $GITHUB_SHA" >> deploy/build_info.txt
        echo "Build number: $GITHUB_RUN_NUMBER" >> deploy/build_info.txt
        
        # Create database initialization script
        cat > deploy/init_db.sh << 'EOF'
        #!/bin/bash
        export PYTHONPATH=.
        python -c "from db.database import Database; db = Database(); db.create_tables()"
        echo "Database tables created successfully"
        EOF
        chmod +x deploy/init_db.sh
        
        # Create simple deployment documentation
        cat > deploy/README.md << 'EOF'
        # BCBS Values Deployment Package
        
        ## Quick Start
        1. Install dependencies: `pip install -r requirements.txt`
        2. Set up environment variables (see .env.example)
        3. Initialize database: `./init_db.sh`
        4. Start the application: `gunicorn --bind 0.0.0.0:5000 main:app`
        
        ## Environment Variables
        - DATABASE_URL: PostgreSQL connection string
        - FLASK_SECRET_KEY: Secret key for Flask sessions
        - NARRPR_USERNAME: Username for NARRPR API access
        - NARRPR_PASSWORD: Password for NARRPR API access
        - PACS_API_KEY: API key for PACS data source
        EOF
        
        # List all files in the deployment package
        echo "Deployment package contents:"
        find deploy -type f | sort
    
    # Upload deployment package as artifact
    - name: Upload deployment package
      uses: actions/upload-artifact@v3
      with:
        name: deployment-package
        path: deploy/